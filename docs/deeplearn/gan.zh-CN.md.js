webpackJsonp([28],{1283:function(n,s){n.exports={content:["article",["p","GAN(Generative Adversarial Networks)\u751f\u6210\u5bf9\u6297\u7f51\u7edc\uff0c\u7531\u4e8e\u5176\u751f\u6210\u5408\u6210\u7ed3\u679c\u7684\u80fd\u529b\u4e00\u76f4\u662f\u6df1\u5ea6\u5b66\u4e60\u4e2d\u4e00\u4e2a\u6d3b\u8dc3\u7684\u7814\u7a76\u9886\u57df\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u4f1a\u6784\u5efa\u4e00\u4e2a\u4f8b\u5b50\u6765\u5b9e\u73b0\u4e00\u4e2a\u7b80\u5355\u7684GAN Network\u3002"],["h2","\u751f\u6210\u7f51\u7edc vs \u5bf9\u6297\u7f51\u7edc"],["p","GAN\u662f\u7531\u751f\u6210\u7f51\u7edc\u548c\u9274\u522b\u7f51\u7edc\u4e24\u90e8\u5206\u7ec4\u6210\u7684\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b83\u5229\u7528\u4e24\u4e2a\u795e\u7ecf\u7f51\u7edc\u7684\u5bf9\u6297\u8fc7\u7a0b\uff0c\u4e92\u76f8\u7ade\u4e89\u8fbe\u5230\u4e00\u4e2a\u5e73\u8861\u70b9\u3002\u751f\u6210\u7f51\u7edc\u8d1f\u8d23\u751f\u6210\u6570\u636e\uff0c\u8fd9\u4e9b\u6570\u636e\u7684\u76ee\u6807\u5c31\u662f\u4e0d\u65ad\u7684\u903c\u8fd1\u771f\u5b9e\u6570\u636e\u3002\u9274\u522b\u7f51\u7edc\u5219\u662f\u6765\u8fa8\u522b\u751f\u6210\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\uff0c\u9274\u522b\u7f51\u7edc\u7684\u6838\u5fc3\u5176\u5b9e\u662f\u5206\u7c7b\u7f51\u7edc\u3002"],["p","\u4f8b\u5982\u4e00\u4efd\u90ae\u4ef6\u4e2d\u6709\u82e5\u5e72\u5355\u8bcd\uff0c\u9274\u522b\u7f51\u7edc\u53ef\u4ee5\u5224\u65ad\u8fd9\u5c01\u90ae\u4ef6\u662f\u5426\u662f\u5783\u573e\u90ae\u4ef6\u3002\u53ef\u4ee5\u770b\u4f5c\u795e\u7ecf\u7f51\u7edc\u901a\u8fc7\u90ae\u4ef6\u4e2d\u7684\u7279\u5f81\u6765\u5224\u65ad\u5b83\u662f\u5426\u662f\u5783\u573e\u90ae\u4ef6\uff0c\u76f8\u53cd\u7684\uff0c\u5f53\u5f97\u77e5\u4e00\u4efd\u90ae\u4ef6\u4e3a\u5783\u573e\u90ae\u4ef6\u65f6\uff0c\u5982\u4f55\u6784\u9020\u7279\u5f81\u6570\u636e\u6765\u6b3a\u9a97\u9274\u522b\u7f51\u7edc\u544a\u8bc9\u5b83\u8fd9\u5e76\u975e\u662f\u4e00\u4efd\u5783\u573e\u90ae\u4ef6\uff0c\u8fd9\u5c31\u662f\u751f\u6210\u7f51\u7edc\u548c\u9274\u522b\u7f51\u7edc\u7684\u5bf9\u6297\u8fc7\u7a0b"],["h2","GAN \u5982\u4f55\u5de5\u4f5c"],["p","\u751f\u6210\u5668\u521b\u5efa\u65b0\u7684\u6d4b\u8bd5\u6570\u636e\uff0c\u7136\u540e\u9274\u522b\u7f51\u7edc\u901a\u8fc7\u8bc4\u4f30\u5224\u65ad\u65b0\u7684\u6570\u636e\u662f\u5426\u5c5e\u4e8e\u771f\u5b9e\u7684\u6d4b\u8bd5\u6570\u636e\u3002\u63a5\u4e0b\u6765\u4ee5\u56fe\u7247\u751f\u6210\u7f51\u7edc\u4e3a\u4f8b"],["ul",["li",["p","\u751f\u6210\u5668\u751f\u6210\u968f\u673a\u8f93\u5165\u4ea7\u751f\u4e00\u5f20\u56fe\u7247\u3002"]],["li",["p","\u751f\u6210\u7684\u56fe\u7247\u548c\u771f\u5b9e\u56fe\u7247\u4e00\u8d77\u4f5c\u4e3a\u8f93\u5165\u7531\u9274\u522b\u7f51\u7edc\u9274\u522b"]],["li",["p","\u9274\u522b\u7f51\u7edc\u6839\u636e\u8f93\u5165\u56fe\u7247\u5806\u5176\u53ef\u80fd\u6027\u8fdb\u884c\u9884\u4f30\uff0c1\u4ee3\u8868\u4e3a\u771f\u5b9e\u6570\u636e\uff0c0\u4ee3\u8868\u4f2a\u9020\u6570\u636e"]]],["h2","\u4ee3\u7801\u5b9e\u73b0"],["pre",{lang:null,highlighted:'from __future__ import print_function<span class="token punctuation">,</span> division\n\nfrom keras<span class="token punctuation">.</span>datasets import mnist\nfrom keras<span class="token punctuation">.</span>layers import Input<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> Reshape<span class="token punctuation">,</span> Flatten\nfrom keras<span class="token punctuation">.</span>layers import BatchNormalization\nfrom keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>advanced_activations import LeakyReLU\nfrom keras<span class="token punctuation">.</span>models import Sequential<span class="token punctuation">,</span> Model\nfrom keras<span class="token punctuation">.</span>optimizers import Adam\n\nimport matplotlib<span class="token punctuation">.</span>pyplot as plt\n\nimport numpy as np\n\n\nclass GanNetwork<span class="token punctuation">:</span>\n\n    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        self<span class="token punctuation">.</span>img_rows <span class="token operator">=</span> <span class="token number">28</span>\n        self<span class="token punctuation">.</span>img_cols <span class="token operator">=</span> <span class="token number">28</span>\n        self<span class="token punctuation">.</span>channels <span class="token operator">=</span> <span class="token number">1</span>\n        self<span class="token punctuation">.</span>img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_rows<span class="token punctuation">,</span> self<span class="token punctuation">.</span>img_cols<span class="token punctuation">,</span> self<span class="token punctuation">.</span>channels<span class="token punctuation">)</span>\n\n        optimizer <span class="token operator">=</span> <span class="token function">Adam</span><span class="token punctuation">(</span><span class="token number">0.0002</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>\n\n        # Build <span class="token operator">and</span> compile the discriminator\n        self<span class="token punctuation">.</span>discriminator <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">build_discriminator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n        self<span class="token punctuation">.</span>discriminator<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">\'binary_crossentropy\'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">\'accuracy\'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>\n\n        # Build <span class="token operator">and</span> compile the generator\n        self<span class="token punctuation">.</span>generator <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">build_generator</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n        self<span class="token punctuation">.</span>generator<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">\'binary_crossentropy\'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">)</span>\n\n        # The generator takes noise as input <span class="token operator">and</span> generated imgs\n        z <span class="token operator">=</span> <span class="token function">Input</span><span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        img <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">generator</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span>\n\n        # <span class="token keyword">For</span> the combined model we will only train the generator\n        self<span class="token punctuation">.</span>discriminator<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>\n\n        # The valid takes generated images as input <span class="token operator">and</span> determines validity\n        valid <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">discriminator</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span>\n\n        # The combined model  <span class="token punctuation">(</span>stacked generator <span class="token operator">and</span> discriminator<span class="token punctuation">)</span> takes\n        # noise as input <span class="token operator">=</span><span class="token operator">></span> generates images <span class="token operator">=</span><span class="token operator">></span> determines validity\n        self<span class="token punctuation">.</span>combined <span class="token operator">=</span> <span class="token function">Model</span><span class="token punctuation">(</span>z<span class="token punctuation">,</span> valid<span class="token punctuation">)</span>\n        self<span class="token punctuation">.</span>combined<span class="token punctuation">.</span><span class="token function">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">\'binary_crossentropy\'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">)</span>\n\n    def <span class="token function">build_generator</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>\n\n        noise_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token punctuation">)</span>\n\n        model <span class="token operator">=</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span>noise_shape<span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">LeakyReLU</span><span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">BatchNormalization</span><span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">LeakyReLU</span><span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">BatchNormalization</span><span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">LeakyReLU</span><span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">BatchNormalization</span><span class="token punctuation">(</span>momentum<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token function">prod</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">\'tanh\'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Reshape</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span>\n\n        model<span class="token punctuation">.</span><span class="token function">summary</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n        noise <span class="token operator">=</span> <span class="token function">Input</span><span class="token punctuation">(</span>shape<span class="token operator">=</span>noise_shape<span class="token punctuation">)</span>\n        img <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>noise<span class="token punctuation">)</span>\n\n        return <span class="token function">Model</span><span class="token punctuation">(</span>noise<span class="token punctuation">,</span> img<span class="token punctuation">)</span>\n\n    def <span class="token function">build_discriminator</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>\n\n        img_shape <span class="token operator">=</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_rows<span class="token punctuation">,</span> self<span class="token punctuation">.</span>img_cols<span class="token punctuation">,</span> self<span class="token punctuation">.</span>channels<span class="token punctuation">)</span>\n\n        model <span class="token operator">=</span> <span class="token function">Sequential</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Flatten</span><span class="token punctuation">(</span>input_shape<span class="token operator">=</span>img_shape<span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">LeakyReLU</span><span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">LeakyReLU</span><span class="token punctuation">(</span>alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token function">Dense</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">\'sigmoid\'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        model<span class="token punctuation">.</span><span class="token function">summary</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n        img <span class="token operator">=</span> <span class="token function">Input</span><span class="token punctuation">(</span>shape<span class="token operator">=</span>img_shape<span class="token punctuation">)</span>\n        validity <span class="token operator">=</span> <span class="token function">model</span><span class="token punctuation">(</span>img<span class="token punctuation">)</span>\n\n        return <span class="token function">Model</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> validity<span class="token punctuation">)</span>\n\n    def <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> save_interval<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>\n\n        # Load the dataset\n        <span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> _<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> mnist<span class="token punctuation">.</span><span class="token function">load_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n        # Rescale <span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">to</span> <span class="token number">1</span>\n        X_train <span class="token operator">=</span> <span class="token punctuation">(</span>X_train<span class="token punctuation">.</span><span class="token function">astype</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">127.5</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">127.5</span>\n        X_train <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">expand_dims</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>\n\n        half_batch <span class="token operator">=</span> <span class="token function">int</span><span class="token punctuation">(</span>batch_size <span class="token operator">/</span> <span class="token number">2</span><span class="token punctuation">)</span>\n\n        <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>\n\n            # <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>\n            #  Train Discriminator\n            # <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>\n\n            # <span class="token keyword">Select</span> a random half batch of images\n            idx <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">randint</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> half_batch<span class="token punctuation">)</span>\n            imgs <span class="token operator">=</span> X_train<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>\n\n            noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>half_batch<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n\n            # Generate a half batch of new images\n            gen_imgs <span class="token operator">=</span> self<span class="token punctuation">.</span>generator<span class="token punctuation">.</span><span class="token function">predict</span><span class="token punctuation">(</span>noise<span class="token punctuation">)</span>\n\n            # Train the discriminator\n            d_loss_real <span class="token operator">=</span> self<span class="token punctuation">.</span>discriminator<span class="token punctuation">.</span><span class="token function">train_on_batch</span><span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token function">ones</span><span class="token punctuation">(</span><span class="token punctuation">(</span>half_batch<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n            d_loss_fake <span class="token operator">=</span> self<span class="token punctuation">.</span>discriminator<span class="token punctuation">.</span><span class="token function">train_on_batch</span><span class="token punctuation">(</span>gen_imgs<span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token function">zeros</span><span class="token punctuation">(</span><span class="token punctuation">(</span>half_batch<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n            d_loss <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>d_loss_real<span class="token punctuation">,</span> d_loss_fake<span class="token punctuation">)</span>\n\n\n            # <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>\n            #  Train Generator\n            # <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>\n\n            noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n\n            # The generator wants the discriminator <span class="token keyword">to</span> label the generated samples\n            # as valid <span class="token punctuation">(</span>ones<span class="token punctuation">)</span>\n            valid_y <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token function">array</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> batch_size<span class="token punctuation">)</span>\n\n            # Train the generator\n            g_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>combined<span class="token punctuation">.</span><span class="token function">train_on_batch</span><span class="token punctuation">(</span>noise<span class="token punctuation">,</span> valid_y<span class="token punctuation">)</span>\n\n            # Plot the progress\n            print <span class="token punctuation">(</span><span class="token string">"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]"</span> % <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> d_loss<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token operator">*</span>d_loss<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> g_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>\n\n            # <span class="token keyword">If</span> at save interval <span class="token operator">=</span><span class="token operator">></span> save generated image samples\n            <span class="token keyword">if</span> epoch % save_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>\n                self<span class="token punctuation">.</span><span class="token function">save_imgs</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>\n\n    def <span class="token function">save_imgs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>\n        r<span class="token punctuation">,</span> c <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span>\n        noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span><span class="token function">normal</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>r <span class="token operator">*</span> c<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>\n        gen_imgs <span class="token operator">=</span> self<span class="token punctuation">.</span>generator<span class="token punctuation">.</span><span class="token function">predict</span><span class="token punctuation">(</span>noise<span class="token punctuation">)</span>\n\n        # Rescale images <span class="token number">0</span> <span class="token operator">-</span> <span class="token number">1</span>\n        gen_imgs <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> gen_imgs <span class="token operator">+</span> <span class="token number">0.5</span>\n\n        fig<span class="token punctuation">,</span> axs <span class="token operator">=</span> plt<span class="token punctuation">.</span><span class="token function">subplots</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> c<span class="token punctuation">)</span>\n        cnt <span class="token operator">=</span> <span class="token number">0</span>\n        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span>r<span class="token punctuation">)</span><span class="token punctuation">:</span>\n            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token function">range</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">:</span>\n                axs<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">imshow</span><span class="token punctuation">(</span>gen_imgs<span class="token punctuation">[</span>cnt<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">\'gray\'</span><span class="token punctuation">)</span>\n                axs<span class="token punctuation">[</span>i<span class="token punctuation">,</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">axis</span><span class="token punctuation">(</span><span class="token string">\'off\'</span><span class="token punctuation">)</span>\n                cnt <span class="token operator">+=</span> <span class="token number">1</span>\n        filename <span class="token operator">=</span> <span class="token string">"images/mnist_{:d}.png"</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>\n        fig<span class="token punctuation">.</span><span class="token function">savefig</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span>\n        plt<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n\n\n<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">\'__main__\'</span><span class="token punctuation">:</span>\n    gan <span class="token operator">=</span> <span class="token function">GanNetwork</span><span class="token punctuation">(</span><span class="token punctuation">)</span>\n    gan<span class="token punctuation">.</span><span class="token function">train</span><span class="token punctuation">(</span>epochs<span class="token operator">=</span><span class="token number">3000</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> save_interval<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span>'},["code","from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten\nfrom keras.layers import BatchNormalization\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n\nclass GanNetwork:\n\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n        # Build and compile the generator\n        self.generator = self.build_generator()\n        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n        # The generator takes noise as input and generated imgs\n        z = Input(shape=(100,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The valid takes generated images as input and determines validity\n        valid = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator) takes\n        # noise as input => generates images => determines validity\n        self.combined = Model(z, valid)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    def build_generator(self):\n\n        noise_shape = (100,)\n\n        model = Sequential()\n\n        model.add(Dense(256, input_shape=noise_shape))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n\n        model.summary()\n\n        noise = Input(shape=noise_shape)\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        img_shape = (self.img_rows, self.img_cols, self.channels)\n\n        model = Sequential()\n\n        model.add(Flatten(input_shape=img_shape))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n        model.summary()\n\n        img = Input(shape=img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128, save_interval=50):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n\n        half_batch = int(batch_size / 2)\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X_train.shape[0], half_batch)\n            imgs = X_train[idx]\n\n            noise = np.random.normal(0, 1, (half_batch, 100))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            noise = np.random.normal(0, 1, (batch_size, 100))\n\n            # The generator wants the discriminator to label the generated samples\n            # as valid (ones)\n            valid_y = np.array([1] * batch_size)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch(noise, valid_y)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n            # If at save interval => save generated image samples\n            if epoch % save_interval == 0:\n                self.save_imgs(epoch)\n\n    def save_imgs(self, epoch):\n        r, c = 5, 5\n        noise = np.random.normal(0, 1, (r * c, 100))\n        gen_imgs = self.generator.predict(noise)\n\n        # Rescale images 0 - 1\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n                axs[i,j].axis('off')\n                cnt += 1\n        filename = \"images/mnist_{:d}.png\".format(epoch)\n        fig.savefig(filename)\n        plt.close()\n\n\nif __name__ == '__main__':\n    gan = GanNetwork()\n    gan.train(epochs=3000, batch_size=32, save_interval=200)"]],["h2","\u5f15\u7528"],["ul",["li",["p",["a",{title:null,href:"https://skymind.ai/wiki/generative-adversarial-network-gan"},"A Beginner's Guide to Generative Adversarial Networks (GANs)"]]],["li",["p",["a",{title:null,href:"https://blog.paperspace.com/implementing-gans-in-tensorflow/"},"Building a simple Generative Adversarial Network (GAN) using TensorFlow"]]]]],meta:{order:1,title:"\u751f\u6210\u5bf9\u6297\u7f51\u7edcGAN",type:"\u5165\u95e8",filename:"docs/deeplearn/gan.zh-CN.md"},toc:["ul",["li",["a",{className:"bisheng-toc-h2",href:"#\u751f\u6210\u7f51\u7edc-vs-\u5bf9\u6297\u7f51\u7edc",title:"\u751f\u6210\u7f51\u7edc vs \u5bf9\u6297\u7f51\u7edc"},"\u751f\u6210\u7f51\u7edc vs \u5bf9\u6297\u7f51\u7edc"]],["li",["a",{className:"bisheng-toc-h2",href:"#GAN-\u5982\u4f55\u5de5\u4f5c",title:"GAN \u5982\u4f55\u5de5\u4f5c"},"GAN \u5982\u4f55\u5de5\u4f5c"]],["li",["a",{className:"bisheng-toc-h2",href:"#\u4ee3\u7801\u5b9e\u73b0",title:"\u4ee3\u7801\u5b9e\u73b0"},"\u4ee3\u7801\u5b9e\u73b0"]],["li",["a",{className:"bisheng-toc-h2",href:"#\u5f15\u7528",title:"\u5f15\u7528"},"\u5f15\u7528"]]]}}});